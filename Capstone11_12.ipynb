{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone11-12.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SIkhGZ2YkcWH"
      ],
      "authorship_tag": "ABX9TyOK3qjYKoJb2Lmt3eHA5nec",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauren-esser/Better-Stock-Market-Prediction/blob/master/Capstone11_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v1si4QNR3QI"
      },
      "source": [
        "#Final Project Submission:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3XGAJiTR6Tj"
      },
      "source": [
        "**Student Name:** Lauren Esser\n",
        "\n",
        "**Student Pace:** Full Time\n",
        "\n",
        "**Scheduled Project Review Date/Time:**  \n",
        "\n",
        "**Instructor Name:** James Irving\n",
        "\n",
        "**Blog Post URLS:**  https://lauren-esser.github.io/how_to_use_newsapi and "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSw-x3WESIjh"
      },
      "source": [
        "#Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHH93unLSKkj"
      },
      "source": [
        "An Abstract section that briefly explains your problem, your methodology, and your findings, and business recommendations as a result of your findings. This section should be 1-2 paragraphs long.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLKNK6x3Ts0v"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il5uJHiXT2ex"
      },
      "source": [
        "#set numpy random seed\n",
        "import numpy as np\n",
        "np.random.seed(1919)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ6z4dm-T218"
      },
      "source": [
        "#set tensor random seed\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1919)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVLnEWsYTujD"
      },
      "source": [
        "#then import other libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import os, glob\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk import FreqDist\n",
        "from nltk.collocations import *\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima_model import ARMA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Embedding, Masking\n",
        "from tensorflow.keras import optimizers \n",
        "from tensorflow.keras.regularizers import l2\n",
        "import itertools\n",
        "import statsmodels.api as sm\n",
        "from matplotlib.pylab import rcParams\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9hTtfQ-UdVI"
      },
      "source": [
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wspf0qVUrgM"
      },
      "source": [
        "%cd ~\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6tjz8moU2Gh"
      },
      "source": [
        "!ls \"/gdrive/My Drive/Colab Notebooks/DataSets\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c2SOshwXc86"
      },
      "source": [
        "print(os.path.abspath(os.curdir))\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd565cN7SQj6"
      },
      "source": [
        "#Obtain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdJhpVnkfpgl"
      },
      "source": [
        "#### Obtain Stocks Dataset:\n",
        "1. Go to http://www.kibot.com/free_historical_data.aspx\n",
        "2. Scroll to bottom of page and download \"Tick with bid/ask data\" under IVE(S&P 500 Value Index) \n",
        "3. Upload to Google drive\n",
        "4. Follow below steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZF-FyyFWeYb"
      },
      "source": [
        "#import and assign txt file\n",
        "source_folder = r'/gdrive/My Drive/Colab Notebooks/DataSets/'\n",
        "target_folder = r'/content/'\n",
        "file = glob.glob(source_folder+ 'IVE_tickbidask.txt', recursive = True)\n",
        "file = file[0]\n",
        "file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT1dbt4ggcCq"
      },
      "source": [
        "#define and view txt file\n",
        "stocks = pd.read_csv(file, header = None)\n",
        "stocks.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhDa88vgiGVk"
      },
      "source": [
        "#rename column headers\n",
        "stocks = stocks.rename(columns={0: 'Date', 1:'Time', 2: 'Price', 3:'Bid',\n",
        "                                4: 'Ask', 5:'Size'})\n",
        "stocks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIkhGZ2YkcWH"
      },
      "source": [
        "#### News API: Can only access up to one month of news headlines for free"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy_k0uB5zw0v"
      },
      "source": [
        "#pip install newsapi-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ityz-d3IznaY"
      },
      "source": [
        "# from newsapi import NewsApiClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVZp4WaqK-fA"
      },
      "source": [
        "\n",
        "# connect with API key\n",
        "# newsapi = NewsApiClient(api_key = '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToQECBlJZlPL"
      },
      "source": [
        "#identify news source options\n",
        "# news_sources = newsapi.get_sources()\n",
        "# news_sourcecs_list = []\n",
        "# for sources in news_sources['sources']:\n",
        "#   news_sourcecs_list.append(sources['name'])\n",
        "#   print(sources['name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqcXdTH_L_J6"
      },
      "source": [
        "# #test out newsapi.get_everything for specific date\n",
        "# date = '2020-11-01'\n",
        "# news_headlines_everything = newsapi.get_everything('&from = (date)', '&to = (date1)', language = 'en')\n",
        "                                                \n",
        "# news_titles_everything = []\n",
        "# for article in news_headlines_everything['articles']:\n",
        "#   news_titles_everything.append(article['title'])\n",
        "#   print(article['title'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0CSfHCkOk61"
      },
      "source": [
        "# #create empty list\n",
        "# news_titles = []\n",
        "\n",
        "# #create function\n",
        "# def get_news_titles(date):\n",
        "#   '''Used to get a list of 20 news titles from usatoday on date specified via newsapi.org.\n",
        "\n",
        "#   Args: date = desired date\n",
        "\n",
        "#   Returns: List of 20 news articles from the specified date with the date listed after\n",
        "\n",
        "#   Example: get_news_titles('2020-11-01')'''\n",
        "  \n",
        "#   date = date\n",
        "#   news_headlines_everything = newsapi.get_everything(from_param = (date), to = (date), language = 'en', domains = 'usatoday.com')\n",
        "#   for article in news_headlines_everything['articles']:\n",
        "#     news_titles.append([article['title'], date])\n",
        "#     #print(article['title'])\n",
        "#     #return news_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou2M7gYa0d9t"
      },
      "source": [
        "# get_news_titles('2020-11-01')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUSb13CM08ny"
      },
      "source": [
        "# news_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhYe_oC24QoI"
      },
      "source": [
        "# get_news_titles('2020-10-25')\n",
        "# news_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PeKybtZ4sKa"
      },
      "source": [
        "# len(news_titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqiaSuks9Lfp"
      },
      "source": [
        "# # sunday_news = ['2020-01-05', '2020-01-12', '2020-01-19', '2020-01-26', '2020-02-02', \n",
        "#                '2020-02-09', '2020-02-16', '2020-02-23', '2020-03-01', '2020-03-08',\n",
        "#                '2020-03-15', '2020-03-22', '2020-03-29', '2020-04-05', '2020-04-12',\n",
        "#                '2020-04-19', '2020-04-26', '2020-05-03', '2020-05-10', '2020-05-17',\n",
        "#                '2020-05-24', '2020-05-31', '2020-06-07', '2020-06-14', '2020-06-21',\n",
        "#                '2020-06-28', '2020-07-05', '2020-07-12', '2020-07-19', '2020-07-26', \n",
        "#                '2020-08-02', '2020-08-09', '2020-08-16', '2020-08-23', '2020-08-30',\n",
        "#                '2020-09-06', '2020-09-13', '2020-09-20', '2020-09-27', '2020-10-04', \n",
        "#                '2020-10-11', '2020-10-18', '2020-10-25', '2020-11-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo5Twcuv-9qc"
      },
      "source": [
        "# for date in sunday_news:\n",
        "#   new = get_news_titles(date)\n",
        "#   news_titles.append(new)\n",
        "# return news_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt6AswAGLG9w"
      },
      "source": [
        "#newsapi.get_top_headlines for today\n",
        "# news_headlines = newsapi.get_top_headlines(language = 'en', country = 'us')\n",
        "# news_titles = []\n",
        "# for article in news_headlines['articles']:\n",
        "#   news_titles.append(article['title'])\n",
        "#   print(article['title'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM646mq6f_po"
      },
      "source": [
        "#### Obtain News Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vItcMDVDg-pF"
      },
      "source": [
        "News Category Dataset from Kaggle:\n",
        "1. Go to https://www.kaggle.com/rmisra/news-category-dataset\n",
        "2. Download dataset to your computer\n",
        "3. Upload dataset into your Google Drive folder\n",
        "4. Follow steps below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyn2JyKPgQJW"
      },
      "source": [
        "!ls \"/gdrive/My Drive/Colab Notebooks/DataSets\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxQW3XGtgbJa"
      },
      "source": [
        "print(os.path.abspath(os.curdir))\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M0dx1Nvgec1"
      },
      "source": [
        "source_folder = r'/gdrive/My Drive/Colab Notebooks/DataSets/'\n",
        "target_folder = r'/content/'\n",
        "file = glob.glob(source_folder+ 'archive.zip', recursive = True)\n",
        "file = file[0]\n",
        "file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc00gpz_gkwq"
      },
      "source": [
        "#upzip data\n",
        "zip_path = file\n",
        "!cp '{zip_path}' .\n",
        "\n",
        "!unzip -q archive.zip\n",
        "!rm archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NyPkmyyhj_C"
      },
      "source": [
        "#open file for viewing\n",
        "news = pd.read_json('/gdrive/My Drive/Colab Notebooks/DataSets/News_Category_Dataset_v2.json', lines = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zu0vnx1i4iH"
      },
      "source": [
        "news.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LglEFbnDSQed"
      },
      "source": [
        "#Scrub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQIhHZNiX_qI"
      },
      "source": [
        "### Scrubbing Stocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz5bAH0VOUGP"
      },
      "source": [
        "#check nulls\n",
        "stocks.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9dFabUjleUh"
      },
      "source": [
        "stocks.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxCuo9yjXQxa"
      },
      "source": [
        "#convert date to a datetime column\n",
        "stocks['Date'] = pd.to_datetime(stocks['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1eapxSsXp9U"
      },
      "source": [
        "stocks.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOqD0N_7Xvje"
      },
      "source": [
        "#set date to index\n",
        "stocks.set_index('Date', inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hELeZhv9zItu"
      },
      "source": [
        "stocks.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiyBgKhSbRdM"
      },
      "source": [
        "In order to make sure we are looking at the same time frame for both stocks and news articles, I will slice and save the correct dates for stocks to correspond to the news articles: 2012-01-28 to 2018-05-26 for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXDJwoebQvz"
      },
      "source": [
        "#slice dates\n",
        "stocks = stocks['2012-01-28': '2018-05-26']\n",
        "stocks.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2P9ti6cPE1R"
      },
      "source": [
        "#resample stocks to business day frequency\n",
        "stocks = stocks.resample('B').last()\n",
        "stocks.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A00iGe7xEKAL"
      },
      "source": [
        "#check for duplicates\n",
        "stocks.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxCKdmZ4E1Eu"
      },
      "source": [
        "#drop duplicates\n",
        "stocks.drop_duplicates(keep='last', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae9AP4rRX3nU"
      },
      "source": [
        "stocks.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ5vV8iFTyrQ"
      },
      "source": [
        "#check nulls\n",
        "stocks.ffill(inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELmiGP7x7Tck"
      },
      "source": [
        "stocks.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6OEEqcdp3hn"
      },
      "source": [
        "### Scrubbing News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7alyNMzSph5O"
      },
      "source": [
        "#end date\n",
        "news.date.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX7DtioMpjoy"
      },
      "source": [
        "#start date\n",
        "news.date.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQtITmhrOBi"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BeMZF-Ej4E8"
      },
      "source": [
        "news.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Hua7k_jwZb"
      },
      "source": [
        "news.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OysOZ05qFyh"
      },
      "source": [
        "#check diff categories\n",
        "news.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Opc79Mrh5N"
      },
      "source": [
        "#set index to date\n",
        "news.set_index('date', inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDSAh9Q8rm3m"
      },
      "source": [
        "news.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBXRohWQkBBk"
      },
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVLHAagJj1dZ"
      },
      "source": [
        "# from nltk.tokenize import word_tokenize\n",
        "# from nltk.corpus import stopwords\n",
        "# import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UQFB-oBmI72"
      },
      "source": [
        "#create stopwords list\n",
        "stopwords = stopwords.words('english')\n",
        "stopwords += list(string.punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc6IANcnbUlv"
      },
      "source": [
        "Identifying stop words, punctuation, and tokenizing the news dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrb2snuond6N"
      },
      "source": [
        "#identify patterns to exclude\n",
        "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
        "\n",
        "#create empty list\n",
        "news_tokens = []\n",
        "\n",
        "#iterate through headlines\n",
        "for headline in news.headline:\n",
        "  tokens = nltk.regexp_tokenize(headline, pattern)\n",
        "  stopped_token = [w.lower() for w in tokens if w.lower() not in stopwords]\n",
        "  stopped_token = \" \".join(stopped_token)\n",
        "  news_tokens.append(stopped_token)\n",
        "  news['clean'] = stopped_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9tnbeHDLEfp"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H2X5ATxBomc"
      },
      "source": [
        "news_tokens[:200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN4Qz9lAhgVq"
      },
      "source": [
        "#join into one string\n",
        "news_tokens = \" \".join(news_tokens)\n",
        "news_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj-qNqDWjkj4"
      },
      "source": [
        "#tokenize final set\n",
        "final_tokenize = word_tokenize(news_tokens)\n",
        "final_tokenize[:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXrjrqKPpK6p"
      },
      "source": [
        "#remove 's from list\n",
        "final_tokenize = list(filter(lambda x: x != \"'s\", final_tokenize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyRm2nd7rK7_"
      },
      "source": [
        "final_tokenize = list(filter(lambda x: x != \"u\", final_tokenize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHHtL7j6oUIG"
      },
      "source": [
        "# from nltk import FreqDist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4kSCW7Po_-m"
      },
      "source": [
        "#identify top 50 most freq words\n",
        "freqdist = FreqDist(final_tokenize)\n",
        "most_common = freqdist.most_common(50)\n",
        "most_common"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9aLfidqp_3v"
      },
      "source": [
        "#normlized word frequency of top 50\n",
        "total_word_count = sum(freqdist.values())\n",
        "most_common = freqdist.most_common(50)\n",
        "print('Word\\t\\t\\tNormalized Frequency')\n",
        "for word in most_common:\n",
        "  normalized_frequency = word[1] / total_word_count\n",
        "  print('{}\\t\\t\\t{:.4}'.format(word[0], normalized_frequency))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOk0dAz0sK-l"
      },
      "source": [
        "#from nltk.collocations import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esU_82imrY9i"
      },
      "source": [
        "#create bigram to show word association\n",
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "news_finder = BigramCollocationFinder.from_words(final_tokenize)\n",
        "news_scored = news_finder.score_ngrams(bigram_measures.raw_freq)\n",
        "news_scored[:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhYV7ksspiC"
      },
      "source": [
        "#create mutual information scores\n",
        "news_pmi_finder = BigramCollocationFinder.from_words(final_tokenize)\n",
        "news_pmi_finder.apply_freq_filter(5)\n",
        "news_pmi_scored = news_pmi_finder.score_ngrams(bigram_measures.pmi)\n",
        "news_pmi_scored[:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbotBZ5zbtG5"
      },
      "source": [
        "Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "decPWpWVcIR6"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv7UsX2jbukh"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatize = []\n",
        "for word in final_tokenize:\n",
        "  x = lemmatizer.lemmatize(word)\n",
        "  lemmatize.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK0Q6PsIdalb"
      },
      "source": [
        "lemmatize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83KTNI-ecRfV"
      },
      "source": [
        "Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25bPrZMRcUld"
      },
      "source": [
        "from nltk.stem.porter import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz8RxhPVcW3p"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "stem = []\n",
        "for word in lemmatize:\n",
        "  x = stemmer.stem(word)\n",
        "  stem.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRSBLDMHdvjQ"
      },
      "source": [
        "stem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Nk5cQqe97I"
      },
      "source": [
        "### Applying Above Strategies to DataFrame\n",
        "- code modified from Dylan Lunde \n",
        "[Blog linked here.](https://medium.com/analytics-vidhya/natural-language-processing-nlp-workflow-tutorial-for-binary-classification-in-sci-kit-learn-b9f94c6aaf14)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYqO-83whDCE"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-2xMCYRgfqH"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0z6n4IfAV5"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "news.headline = news.headline.apply(lambda x: tokenizer.tokenize(x.lower()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtQtAF0OhEIm"
      },
      "source": [
        "Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dslzYdH1hNA1"
      },
      "source": [
        "def stop_words(title):\n",
        "  w = [w.lower() for w in title if w.lower() not in stopwords]\n",
        "  return w\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10T_BjJ-hMww"
      },
      "source": [
        "news.headline = news.headline.apply(lambda x: stop_words(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2-l25jfh9aY"
      },
      "source": [
        "Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2ULOpvGiExH"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize(title):\n",
        "  x = [lemmatizer.lemmatize(word) for word in title]\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7zIGTRIiFGL"
      },
      "source": [
        "news.headline = news.headline.apply(lambda x: lemmatize(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CB6RVdPilLu"
      },
      "source": [
        "Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbtT2wXFimw1"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "def stem(title):\n",
        "  stem = \" \".join([stemmer.stem(word) for word in title])\n",
        "  return stem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zml79jEljJ4M"
      },
      "source": [
        "news.headline = news.headline.apply(lambda x: stem(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F689DSbjNfQ"
      },
      "source": [
        "news.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86xW_lb8SQYu"
      },
      "source": [
        "#Explore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVOIpEwbZD5n"
      },
      "source": [
        "### Stocks Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bRHxqWohk_A"
      },
      "source": [
        "###### Line Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vRptZfdZGKM"
      },
      "source": [
        "#line plot of stocks price over the years\n",
        "fig = plt.figure(figsize = (15, 8))\n",
        "plt.plot(stocks['Price'])\n",
        "plt.title('Stock Price Through The Years')\n",
        "plt.ylabel('Price')\n",
        "plt.xlabel('Year');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73mIr_Rx0q3d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er_xD-bkYkjw"
      },
      "source": [
        "###### Dot Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6oVhdqC2LUM"
      },
      "source": [
        "#dot plot of stocks price over the years\n",
        "fig = plt.figure(2, figsize = (15, 8))\n",
        "plt.plot(stocks['Price'], '.')\n",
        "plt.title('Stock Price Through The Years')\n",
        "plt.ylabel('Price')\n",
        "plt.xlabel('Year');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poeuvpivYmkR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z4x5XID4ZrT"
      },
      "source": [
        "###### Rolling Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQyvzMPK4ZHz"
      },
      "source": [
        "#identify rolling mean and rolling standard deviation\n",
        "roll_mean = stocks['Price'].rolling(window = 90, center = False).mean()\n",
        "roll_std = stocks['Price'].rolling(window = 90, center = False).std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiLB48MQ4rt6"
      },
      "source": [
        "#visualize rolling mean, rolling std, and original\n",
        "fig = plt.figure(figsize = (15, 8))\n",
        "plt.plot(stocks['Price'], color = 'blue', label = 'Original')\n",
        "plt.plot(roll_mean, color = 'green', label = 'Rolling Mean')\n",
        "plt.plot(roll_std, color = 'black', label = 'Rolling Std')\n",
        "plt.legend()\n",
        "plt.title('Rolling Mean & Standard Deviation')\n",
        "plt.xlabel('Year')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryDESIE0YoxY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlv7_4wz9Kyf"
      },
      "source": [
        "###### The Dickey-Fuller Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch9VZoNu9KYS"
      },
      "source": [
        "dftest = adfuller(stocks['Price'])\n",
        "\n",
        "dfoutput = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value', '#Lags Used',\n",
        "                                           'Number of Observations Used'])\n",
        "for key, value in dftest[4].items():\n",
        "  dfoutput['Critical Values (%s)' %key] = value\n",
        "print(dftest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qifW0Lj_90uM"
      },
      "source": [
        "print('Results of Dicky-Fuller test: \\n')\n",
        "\n",
        "print(dfoutput)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qufL13LW3pkT"
      },
      "source": [
        "**Summary:**\n",
        "- Not a stationary series\n",
        "- Linear upward trend\n",
        "- Slight drop near the end of 2015.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrTsA9ugYq9X"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Ue9wp0huy-"
      },
      "source": [
        "###### Histograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRa9dxuuh0Xh"
      },
      "source": [
        "#build histogram to check distribution\n",
        "fig, ax = plt.subplots(figsize = (12, 5))\n",
        "ax.hist(stocks['Price'])\n",
        "ax.set_title('Stock Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38Its6qrZCta"
      },
      "source": [
        "###### Density Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tXwqxMMiKPB"
      },
      "source": [
        "#build density plot to check distribution\n",
        "stocks['Price'].plot(kind = 'kde', figsize = (12, 5));\n",
        "ax.set_title('Density Plot of Stock Price')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuOXNlooAa5t"
      },
      "source": [
        "#### Eliminating the trend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AGweExQ0YBR"
      },
      "source": [
        "##### Square Root Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3oKEOx0AeNF"
      },
      "source": [
        "data = pd.Series(np.sqrt(stocks['Price']))\n",
        "fig = plt.figure(figsize = (15, 8))\n",
        "plt.plot(data, color = 'blue')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('sqrt(yearly sales')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrXa0vmXzWmk"
      },
      "source": [
        "##### Log Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoCF47rzAeVn"
      },
      "source": [
        "data = pd.Series(np.log(stocks['Price']))\n",
        "fig = plt.figure(figsize = (15, 8))\n",
        "plt.plot(data, color = 'blue')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('log(yearly sales')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtIunri20g-W"
      },
      "source": [
        "##### Differencing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxLcq63E1lZ0"
      },
      "source": [
        "data_diff = data.diff(periods = 1)\n",
        "data_diff.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HleHEikx1uVN"
      },
      "source": [
        "fig = plt.figure(figsize=(11,7))\n",
        "plt.plot(data_diff, color='blue',label='Stock Price - rolling mean')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Differenced Stock Price series')\n",
        "plt.show(block=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIGUnaTqWGB_"
      },
      "source": [
        "data_diff = data.diff().dropna()\n",
        "data_diff.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPCp3r9dq20n"
      },
      "source": [
        "### News Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gQRLAJ3q8Cu"
      },
      "source": [
        "fig = plt.figure(figsize = (15, 8))\n",
        "g = sns.displot(news.category, height = 5, aspect = 2)\n",
        "g.set_xticklabels(rotation = 80)\n",
        "plt.title('Headline Count of Each Genre');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8dtkWF4rpdf"
      },
      "source": [
        "news['year'] = news.index.to_series().apply(lambda x: x.year)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC8sBi14r2EJ"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qVl4w6hr4k0"
      },
      "source": [
        "sns.displot(news.year)\n",
        "plt.title('Headline Count per Year');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmlrQeHL1q0h"
      },
      "source": [
        "import wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H50NKGsD1dYQ"
      },
      "source": [
        "#visualize top words in news dataframe\n",
        "wc = wordcloud.WordCloud(max_words = 200, width = 500, height = 500)\n",
        "text = news_tokens\n",
        "wc.generate_from_text(text);\n",
        "wc.to_image()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaiKru55KUPo"
      },
      "source": [
        "plt.plot(most_common.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtOafKs4SQR_"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0OLuv7BOw1"
      },
      "source": [
        "## Stocks Time Series Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAws9pSXBT9g"
      },
      "source": [
        "##### Random Walk Model\n",
        "- no specified mean or variance\n",
        "- a strong dependence over time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUx-9rMDEJRW"
      },
      "source": [
        "#series with the specified dates\n",
        "work = pd.date_range('2012-01-28', '2018-05-26', freq = 'B')\n",
        "\n",
        "#white noise error \n",
        "error = np.random.normal(0, 10, len(work))\n",
        "\n",
        "#random walk\n",
        "def random_walk(start, error):\n",
        "  Y_0 = start\n",
        "  cum_error = np.cumsum(error)\n",
        "  Y = cum_error + Y_0\n",
        "  return Y\n",
        "\n",
        "#value of share on first date\n",
        "share_value = random_walk(61, error)\n",
        "\n",
        "shares_series = pd.Series(share_value, index = work)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SvsMVBFF1FL"
      },
      "source": [
        "#plt random walk visualization\n",
        "ax = shares_series.plot(figsize = (15, 8))\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Stock Price')\n",
        "ax.set_title('Random Walk')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvRkmb1wHOzo"
      },
      "source": [
        "##### Random Walk with a Drift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX0Ld5QTHgXt"
      },
      "source": [
        "#series with the specified dates\n",
        "work = pd.date_range('2012-01-28', '2018-05-26', freq = 'B')\n",
        "\n",
        "#white noise error \n",
        "error = np.random.normal(0, 10, len(work))\n",
        "\n",
        "#random walk\n",
        "def random_walk(start, error):\n",
        "  Y_0 = start\n",
        "  #add drift of 8\n",
        "  cum_error = np.cumsum(error + 8)\n",
        "  Y = cum_error + Y_0\n",
        "  return Y\n",
        "\n",
        "#value of share on first date\n",
        "share_value_drift = random_walk(61, error)\n",
        "\n",
        "shares_series_diff = pd.Series(share_value_drift, index = work)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI2LJ8AYHlBP"
      },
      "source": [
        "#plot random walk with drift visualization\n",
        "ax = shares_series_diff.plot(figsize = (15, 8))\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Stock Price')\n",
        "ax.set_title('Random Walk with Drift')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhjuRkqRN_qd"
      },
      "source": [
        "##### Differencing in a Random Walk Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqH1P_syOCRS"
      },
      "source": [
        "#no drift\n",
        "shares_diff = shares_series.diff(periods = 1)\n",
        "\n",
        "fig = plt.figure(figsize = (15, 8))\n",
        "plt.plot(shares_diff)\n",
        "plt.title('Differenced Shares Series')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF-yWTnOO8ke"
      },
      "source": [
        "#drift\n",
        "shares_drift_diff = shares_series_diff.diff(periods = 1)\n",
        "\n",
        "fig = plt.figure(figsize = (15, 8))\n",
        "plt.plot(shares_drift_diff)\n",
        "plt.title('Differenced Shares Series')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7tkmgC9B9uG"
      },
      "source": [
        "##### ARMA Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCmKsjnZdXoH"
      },
      "source": [
        "data_diff.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjTjQQsc6dSY"
      },
      "source": [
        "#set index to be business days\n",
        "data_diff.index = pd.DatetimeIndex(data_diff.index).to_period('B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ztdSpfB9Gv"
      },
      "source": [
        "#plotting the ACF\n",
        "#from statsmodels.graphics.tsaplots import plot_acf\n",
        "fig, ax = plt.subplots(figsize = (8, 3))\n",
        "\n",
        "plot_acf(data_diff, ax = ax, lags = 8);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhruE7zxRAQe"
      },
      "source": [
        "#plotting PACF\n",
        "#from statsmodels.graphics.tsaplots import plot_pacf\n",
        "fig, ax = plt.subplots(figsize= (8, 3))\n",
        "plot_pacf(data_diff, ax = ax, lags = 8);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVHaeROqR8li"
      },
      "source": [
        "#import arma\n",
        "#from statsmodels.tsa.arima_model import ARMA\n",
        "\n",
        "#fit an ARMA 1 model\n",
        "mod_arma = ARMA(data_diff, order = (1,0))\n",
        "res_arma = mod_arma.fit()\n",
        "\n",
        "print(res_arma.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amhcjdlDnTVx"
      },
      "source": [
        "#ARMA 2\n",
        "mod_arma = ARMA(data_diff, order = (2,2))\n",
        "res_arma = mod_arma.fit()\n",
        "\n",
        "print(res_arma.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_yWknDSqb5O"
      },
      "source": [
        "#ARMA 3\n",
        "mod_arma = ARMA(data_diff, order = (4,3))\n",
        "res_arma = mod_arma.fit()\n",
        "\n",
        "print(res_arma.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHK-jQyPrFWC"
      },
      "source": [
        "> Attempted higher order numbers but received RunTime errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTvPy90a3gsf"
      },
      "source": [
        "##### STOCKS TIME SERIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPC_4FXKe-7I"
      },
      "source": [
        "#replace any 0 values\n",
        "stocks_ts = stocks[['Price']]\n",
        "stocks_ts[stocks_ts == 0] = np.nan\n",
        "stocks_ts = stocks_ts.ffill()\n",
        "\n",
        "#select a shorter time period\n",
        "stocks_ts = stocks_ts.loc['2012':'2018']\n",
        "stocks_ts.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLTZYkWL03Hn"
      },
      "source": [
        "#set index to datetime business days\n",
        "stocks_ts.index = pd.DatetimeIndex(stocks_ts.index).to_period('B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RzL0Qrbf2yV"
      },
      "source": [
        "stocks_ts.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9ssx9Ez5ebC"
      },
      "source": [
        "#check for nulls\n",
        "stocks_ts.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkiVJX8UCv5R"
      },
      "source": [
        "len(stocks_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPeCT3O33Xu"
      },
      "source": [
        "#train test split\n",
        "int_split = round(len(stocks_ts)*.8) \n",
        "train = stocks_ts.iloc[:int_split]\n",
        "test = stocks_ts.iloc[int_split:]\n",
        "\n",
        "#visualize\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "train.plot(ax = ax)\n",
        "test.plot(ax = ax);\n",
        "L = plt.legend()\n",
        "L.get_texts()[0].set_text('Train')\n",
        "L.get_texts()[1].set_text('Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVmrmXICd02L"
      },
      "source": [
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#instantiate scaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(train) \n",
        "X_test = scaler.transform(test) \n",
        "\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlxUzuu6gNC7"
      },
      "source": [
        "#convert to dataframe\n",
        "X_train = pd.DataFrame(X_train, index = train.index, columns = ['Price'])\n",
        "X_test = pd.DataFrame(X_test, index = test.index, columns = ['Price'])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "X_train.plot(ax = ax)\n",
        "X_test.plot(ax = ax)\n",
        "L = plt.legend()\n",
        "L.get_texts()[0].set_text('Train')\n",
        "L.get_texts()[1].set_text('Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsdgOsyjgqnm"
      },
      "source": [
        "#set feature number\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "series = X_train.values\n",
        "series = series.reshape((len(series), n_features))\n",
        "series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9iuKJbU6sTo"
      },
      "source": [
        "#from keras.preprocessing.sequence import TimeseriesGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Bh_-Kygz67"
      },
      "source": [
        "#number of timesteps for the sequences \n",
        "length = 50\n",
        "\n",
        "#create time series generator\n",
        "generator = TimeseriesGenerator(series, series, length, batch_size = 32)\n",
        "generator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyrxsElDhTm_"
      },
      "source": [
        "#testing out ind. output\n",
        "ex_X, ex_y = generator[1]\n",
        "ex_X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktbp1IdPhe-2"
      },
      "source": [
        "#create test data\n",
        "test_series = X_test.values \n",
        "test_series = test_series.reshape((len(test_series), n_features))\n",
        "test_gen = TimeseriesGenerator(test_series, test_series, length, batch_size = 32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsESfgwV7cm6"
      },
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
        "# from tensorflow.keras import optimizers \n",
        "# from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQT0DjTu3ivJ"
      },
      "source": [
        "#define generator\n",
        "input_shape = (length, n_features)\n",
        "#number of samples\n",
        "print('Samples: %d' % len(generator))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g6e8qtc66ic"
      },
      "source": [
        "#define model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation = 'relu', input_shape = input_shape))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer= optimizers.Nadam(), loss = 'mse', metrics = ['mse'])\n",
        "\n",
        "display(model.summary())\n",
        "history = model.fit(generator, epochs = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYQnJ3Bn7UIF"
      },
      "source": [
        "results = pd.DataFrame(history.history)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8TnQOF0BMlM"
      },
      "source": [
        "y_hat_test = model.predict(test_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyp1Cvh0pOEU"
      },
      "source": [
        "y_hat_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BAXJPKAETHA"
      },
      "source": [
        "X_test[:length].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp1A8MSFwJzK"
      },
      "source": [
        "X_test[length:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-JhHl_DR85L"
      },
      "source": [
        "# X_test shape is (319, 1)\n",
        "#X_test.index, #how to I add predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC34b5u1jXwq"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "X_train.plot(ax = ax)\n",
        "X_test['Price'].plot(ax = ax, label = 'Test')\n",
        "ax.plot(y_hat_test.flatten(), label = 'Predicted')\n",
        "ax.set_title('S&P 500 - Model 1')\n",
        "L = plt.legend()\n",
        "L.get_texts()[0].set_text('Train')\n",
        "L.get_texts()[1].set_text('Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eowZvfUCz2Pz"
      },
      "source": [
        "#define model 2\n",
        "model2 = Sequential()\n",
        "model2.add(LSTM(units = 64, activation = 'relu', input_shape = input_shape))\n",
        "model2.add(Dense(1))\n",
        "\n",
        "model2.compile(optimizer= optimizers.Nadam(), loss = 'mse', metrics = ['mse'])\n",
        "\n",
        "display(model2.summary())\n",
        "history = model2.fit(generator, epochs = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vypb4Sfc6XZ6"
      },
      "source": [
        "results = pd.DataFrame(history.history)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbNc3IGA6rkH"
      },
      "source": [
        "y_hat_test = model2.predict(generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT-SarRrGBHW"
      },
      "source": [
        "y_hat_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JP-tg15GDji"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS0JExP367uI"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "X_train.plot(ax = ax)\n",
        "X_test.plot(ax = ax, label = 'Test')\n",
        "ax.plot(X_test.index, y_hat_test.flatten(), label = 'Predicted')\n",
        "ax.set_title('S&P 500 - Model 1')\n",
        "L = plt.legend()\n",
        "L.get_texts()[0].set_text('Train')\n",
        "L.get_texts()[1].set_text('Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWGYv4E5ebnQ"
      },
      "source": [
        "##### SARIMA Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqzCFf3KrzNN"
      },
      "source": [
        "- q - auto regressive part of the model. effect of past values into model. \n",
        "- d - amount of differnecing as it identifies the number of lag values to subtract from the current observation\n",
        "- q - moving average part of the model which is used to set the error of the model as a linear combination of the error values observed at previous time points in the past."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkQPIzGQvUZ9"
      },
      "source": [
        "#import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIpvcpo6ed2l"
      },
      "source": [
        "#define p,d,q with value between 0 & 2\n",
        "p = d = q = range(0, 3)\n",
        "\n",
        "#generate diff combos of p, q, & d triplets\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "#generate all diff combos of seasonal p, d, q, triplets\n",
        "pdqs = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKq2TVtuhDT"
      },
      "source": [
        "#import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK63TkG9s93d"
      },
      "source": [
        "# #initialize empty list\n",
        "# answer = []\n",
        "# #iterate through params\n",
        "# for comb in pdq:\n",
        "#   for combs in pdqs:\n",
        "#     try:\n",
        "#       mod = sm.tsa.statespace.SARIMAX(stocks_ts,\n",
        "#                                       order = comb,\n",
        "#                                       seasonal_order = combs,\n",
        "#                                       enforce_stationarity = False, \n",
        "#                                       enforce_invertibility = False)\n",
        "      \n",
        "#       output = mod.fit(maxiter = 200)\n",
        "#       answer.append([comb, combs, output.aic])\n",
        "#       print('ARIMA{} x {}12: AIC Calculated = {}'.format(comb, combs, output.aic))\n",
        "#     except:\n",
        "#       continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmQdkVsZv7Y5"
      },
      "source": [
        "# Find the parameters with minimal AIC value\n",
        "ans_df = pd.DataFrame(answer, columns=['pdq', 'pdqs', 'aic'])\n",
        "ans_df.loc[ans_df['aic'].idxmin()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAdLGLLQWAKP"
      },
      "source": [
        "stocks_ts = stocks_ts.to_timestamp(freq = 'B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgyr0GPsu36F"
      },
      "source": [
        "#plug in optimal parameter values\n",
        "arima_model = sm.tsa.statespace.SARIMAX(stocks_ts, \n",
        "                                        order = (2,1,2),\n",
        "                                        seasonal_order = (1,1,2,12),\n",
        "                                        enforce_stationarity=False,\n",
        "                                        enforce_invertibility=False)\n",
        "\n",
        "#fit model\n",
        "output = arima_model.fit()\n",
        "\n",
        "print(output.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7Rv7Pycvb7u"
      },
      "source": [
        "output.plot_diagnostics(figsize = (15, 18))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf46WIqbaFd3"
      },
      "source": [
        "###### Validating the SARIMA Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Szd3IiwQtct"
      },
      "source": [
        "res = arima_model.filter(output.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaplV-VtQ8Ql"
      },
      "source": [
        "predict = res.get_prediction()\n",
        "pred_conf = predict.conf_int()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1WF3oFdwHFR"
      },
      "source": [
        "#get predictions\n",
        "pred = output.get_prediction(start = pd.to_datetime('2017-06-02'), \n",
        "                             #end = pd.to_datetime('2018-05-07'), \n",
        "                             dynamic = False)\n",
        "pred_conf = pred.conf_int()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr7Vlye1ZZzW"
      },
      "source": [
        "stocks_ts.head(-10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T1geNSzYMfb"
      },
      "source": [
        "rcParams['figure.figsize'] = 15, 6\n",
        "\n",
        "#plot observed\n",
        "ax = stocks_ts['2017-05-26':].plot(label = 'Observed')\n",
        "\n",
        "#plot predicted\n",
        "pred.predicted_mean.plot(ax = ax, label = 'One step ahead Forecast', alpha = 0.9)\n",
        "\n",
        "#set axes labels\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_title('Real and Forecasted S&P 500 Price Values')\n",
        "ax.set_ylabel('S & P 500 Stock Prices')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7qC_QKrbG8W"
      },
      "source": [
        "#real and predicted values\n",
        "stocks_forecasted = pred.predicted_mean.values\n",
        "stocks_truth = stocks_ts['2017-06-02':].values\n",
        "\n",
        "#compute mse\n",
        "mse = ((stocks_forecasted - stocks_truth) ** 2).mean()\n",
        "print('MSE is {}'.format(round(mse, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfksrhXdUjk"
      },
      "source": [
        "###### Dynamic Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Z8LD9UdXyw"
      },
      "source": [
        "pred_dynamic = output.get_prediction(start = pd.to_datetime('2017-06-02'),\n",
        "                                     dynamic = True, \n",
        "                                     full_results = True)\n",
        "pred_dynamic_conf = pred_dynamic.conf_int()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnmEw-dteRhF"
      },
      "source": [
        "stocks_forecasted = pred.predicted_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N1mmNSNdXqB"
      },
      "source": [
        "ax = stocks_ts['2017-06-02':].plot(label = 'Observed', figsize = (15, 8))\n",
        "pred_dynamic.predicted_mean.plot(label = 'Dynamic Forecast', ax = ax)\n",
        "\n",
        "# ax.fill_between(pred_dynamic_conf.index,\n",
        "#                 pred_dynamic_conf.iloc[:, 0],\n",
        "#                 pred_dynamic_conf.iloc[:, 1], color='g', alpha=.3)\n",
        "\n",
        "ax.fill_betweenx(ax.get_ylim(), pd.to_datetime('2018-05-11'), \n",
        "                 stocks_forecasted.index[-1], alpha=.1, zorder=-1)\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('S&P 500 Price')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hskVuVIewwy"
      },
      "source": [
        "#real and predicted values\n",
        "stocks_forecasted = pred_dynamic.predicted_mean.values\n",
        "stocks_truth = stocks_ts['2017-06-02':].values\n",
        "\n",
        "#compute mse\n",
        "mse = ((stocks_forecasted - stocks_truth) ** 2).mean()\n",
        "print('MSE is {}'.format(round(mse, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9kYfDElfBv-"
      },
      "source": [
        "###### Producing and Visualizing Forecasts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5afX-sXfLSU"
      },
      "source": [
        "#forecast 365 steps into future\n",
        "prediction = output.get_forecast(steps = 365)\n",
        "\n",
        "#get conf intervals\n",
        "pred_conf = prediction.conf_int()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCmgL8BifLGP"
      },
      "source": [
        "# Plot future predictions with confidence intervals\n",
        "ax = stocks_ts.plot(label='Observed', figsize=(15, 8))\n",
        "prediction.predicted_mean.plot(ax=ax, label='Forecast')\n",
        "ax.fill_between(pred_conf.index,\n",
        "                pred_conf.iloc[:, 0],\n",
        "                pred_conf.iloc[:, 1], color='k', alpha=0.25)\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('S&P 500 Price')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBYCE7bGZn-c"
      },
      "source": [
        "## Try PMDArima here\n",
        "- https://pypi.org/project/pmdarima/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjagRr--eYH9"
      },
      "source": [
        "## News Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyruBg-NouTt"
      },
      "source": [
        "Going to want to use basic RNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9_E2hJptu4l"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing.text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os1Ubqw9t84Y"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(news.headline)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(news.headline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OppaosluuGQp"
      },
      "source": [
        "sequences[100][:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUGbCFH4uV2s"
      },
      "source": [
        "idx_word = tokenizer.index_word\n",
        "' '.join(idx_word[w] for w in sequences[100][:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaWo_4aavf4S"
      },
      "source": [
        "num_words = len(idx_word) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkYTa7pJwz9p"
      },
      "source": [
        "num_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDpQLGjXw7SI"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K24ykEnku268"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim = num_words, input_length = len(X_train), \n",
        "                    output_dim = 100, trainable = False))\n",
        "model.add(Masking())\n",
        "model.add(LSTM(64, return_sequences = False))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_words, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Sgi7RnxmcG"
      },
      "source": [
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNpwa219xpkV"
      },
      "source": [
        "callback = EarlyStopping(monitor = 'valu_loss', patience = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aj9eUH5xu8M"
      },
      "source": [
        "history = model.fit(X_train, X_train, batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16aHO_l7u3Su"
      },
      "source": [
        "## Do I need to Train Test SPlit?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiNc9F9alHnB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUWxagRebcC"
      },
      "source": [
        "#train, test, split\n",
        "X_train, X_test = train_test_split(news.headline, test_size = .2,\n",
        "                                                    random_state = 1212)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK43hkUtSQJj"
      },
      "source": [
        "#Interpret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82Gj6RMRSXmy"
      },
      "source": [
        "#Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5HwAoqMSY2I"
      },
      "source": [
        "#Future Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk4DM6VxRpyE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}